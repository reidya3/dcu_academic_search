{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not On Doras\n",
    "\n",
    "This notebook details the method used to find missing publications on doras. For finding the missing publications, I used the standard Levenshtein distance similarity ratio and regular expressions. I had to specify specific thresholds for certain researchers, however, the majority were set at  a default (90). However, there were some rogue publications that were above such a threshold but still dissimilar. I hardcoded such files into  a csv file called mismatches_not_on_doras. This may a problem for future iterations. I tried other methods such as  the cosine similarity ratio using word n-gram, character n-grams and ‘char_wb’( which creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space) to try and catch the rogue publications .  However, none provided a  clear threshold  for which I  could separate the rogues from the similar publications and in some cases, the cosine similarity ratio did not find the nearest title!\n",
    "\n",
    "\n",
    "**Example:** The google scholar  title was \"Computer Vision for Lifelogging: Characterizing Everyday Activities Based on Visual Semantics\" the nearest title on doras was actually \"Computer Vision for Lifelogging\" . However, the cosine similarity ratio suggested \"Characterizing everyday activities from visual lifelogs based on enhancing concept representation.\" as the nearest title. So, in the end, I abandoned using the cosine  similarity ratio.\n",
    "\n",
    "This notebook contains **three** key components:\n",
    "\n",
    "1. Creating methods that will help me identify the missing and rogue publications. In addition, recounciling the two versions of \n",
    "   doras (the faculty page and a researcher's page) as there are some publications that appeared in a researchers page that did not appear in the faculty page and vice versa. I also dropped redundant columns.\n",
    "\n",
    "2. Perfoming the splitting.\n",
    "\n",
    "3. Creating a pandas dataframe(detailed below) for the missing doras and rogue doras publications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "researchers = pd.read_csv(\"../data/SOC_Researchers_with_doras_names.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe containing publications that are in a researcher's google scholar profile but not on doras\n",
    "not_on_doras = pd.DataFrame(columns=['Research name','Publication Title','Author List','Conf/Journal Details','Citation count','Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating functions that will find the missing doras publications and reconcile the  two versions of Doras \n",
    "\n",
    "**add_mis_matches** method that assists in the development of a dataframe that contains  mismatched/rogue publications\n",
    "\n",
    "**check_years** checks if there is a year present in the google scholar publication title and the nearest publication title in doras\n",
    "\n",
    "**equal_years**  tests if the year in a  google scholar publications title and the year in  the nearest publication title in doras are the same\n",
    "\n",
    "**check_ncir** another method testing whether the year in a publications title containing \"NICIR\" and the year in the nearest publication title in doras are the same. Note, the year is in the format NCIR-19 (for example) so I could not simply use the method above.\n",
    "\n",
    "**check_sr** another method testing whether the year in a publications title containing \"shared task (SR\" and the year in the nearest publication title in doras are the same. Note, the year is in the format SR'19 or SR’19 so so I could not simply use the method above.\n",
    "\n",
    "**check_wmt** checks whether a scholar publication title  contains wmt and the nearest publication title in doras also contain wmt\n",
    "\n",
    "**equal_wmt**  another method testing whether the year in a publications title containing \"wmt\" and the year in the nearest publication title in doras are the same. Note, the year is in the format SR'19 or SR’19 so so I could not simply used the method above.\n",
    "\n",
    "**reconcile_doras** a method used to recouncile the two versions of doras (the faculty page and a researcher's page) as there are some publications that appeared in a researchers page that did not appear in the faculty page and vice versa. I also dropped redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mis_match_title = []\n",
    "list_nearest_title  = []\n",
    "list_score = []\n",
    "list_researcher = []\n",
    "list_year = []\n",
    "# method that assists in the development of a dataframe that contains  mismatched/rogue publications \n",
    "def add_mis_matches(research, title,near,score,year):\n",
    "    list_researcher.append(research)\n",
    "    list_mis_match_title.append(title)\n",
    "    list_nearest_title.append(near)\n",
    "    list_score.append(score)\n",
    "    list_year.append(year)\n",
    "#checks if there is a year present in the publication title and the nearest publication title in doras\n",
    "def check_years(title,near_title):\n",
    "    try:\n",
    "        year1 = re.findall(\"[2][0][0-9]{2}\",title)[0]\n",
    "        year2 = re.findall(\"[2][0][0-9]{2}\",near_title)[0]\n",
    "    except IndexError:\n",
    "        return False\n",
    "    return True\n",
    "# tests if the year in a publications title and the year in  the nearest publication title in doras are the same\n",
    "def equal_year(title,near_title):\n",
    "    year1 = re.findall(\"[2][0-9]{3}\",title)[0]\n",
    "    year2 = re.findall(\"[2][0-9]{3}\",near_title)[0]\n",
    "    return year1 == year2\n",
    "#another method testing whether the year in a publications title containing \"NICIR\" and the year in the nearest publication title in doras are the same \n",
    "def check_ncir(title,near_title):\n",
    "    year1 = re.findall(\"NTCIR-[0-9]{2}\",title)[0]\n",
    "    year2 = re.findall(\"NTCIR-[0-9]{2}\",near_title)[0]\n",
    "    return year1 == year2\n",
    "#another method testing whether the year in a publications title containing \"shared task (SR\" and the year in the nearest publication title in doras are the same \n",
    "def check_sr(title, near_title):\n",
    "    year1 = re.findall(\"(SR[’|'][0-9]{2})\",title)[0][-2:]\n",
    "    year2 = re.findall(\"(SR[’|'][0-9]{2})\",near_title)[0][-2:]\n",
    "    return year1 == year2\n",
    "# checks whether a  publication title  contains wmt and the nearest publication title in doras also contain wmt\n",
    "def check_wmt(title, near_title):\n",
    "    try:\n",
    "        year1 = re.findall(\"wmt[0-9]{2}\",title.lower())[0][-2:]\n",
    "        year2 = re.findall(\"wmt[0-9]{2}\",near_title.lower())[0][-2:]\n",
    "    except IndexError:\n",
    "        return False\n",
    "    return True\n",
    "# another method testing whether the year in a publications title containing \"wmt\" and the year in the nearest publication title in doras are the same \n",
    "def equal_wmt(title,near_title):\n",
    "        year1 = re.findall(\"wmt[0-9]{2}\",title.lower())[0][-2:]\n",
    "        year2 = re.findall(\"wmt[0-9]{2}\",near_title.lower())[0][-2:]\n",
    "        return year1 == year2\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recounciling the doras profile verion and doras faculty page as there is publications that do not appear on both!\n",
    "def reconcile_doras(value,doras_name,doras_df,doras_soc_df):\n",
    "    soc = doras_soc_df[doras_soc_df[\"Author List\"].str.contains(doras_name)]\n",
    "\n",
    "    soc = soc[[\n",
    "     'Publication Title',\n",
    "     'Author List',\n",
    "     'Conf/Journal Details',\n",
    "     'Year',\n",
    "     'ISBN',\n",
    "     'ISSN',\n",
    "     'Item Type',\n",
    "     'Event Type',\n",
    "     'Refereed',\n",
    "     'Date of Award',\n",
    "     'Supervisor(s)',\n",
    "     'Uncontrolled Keywords',\n",
    "     'Subject',\n",
    "     'DCU Faculties and Centres',\n",
    "     'Use License',\n",
    "     'ID Code',\n",
    "     'Deposited On',\n",
    "     'Published in',\n",
    "     'Publisher',\n",
    "     'Official URL',\n",
    "     'Copyright Information',\n",
    "     'Funders',\n",
    "     'Additional Information',\n",
    "     'Tweets',\n",
    "     'Mendeley Readers']]\n",
    "\n",
    "    soc.insert(0, 'Research name', value)\n",
    "\n",
    "\n",
    "    doras_df = doras_df[['Research name', 'Publication Title', 'Author List',\n",
    "       'Conf/Journal Details', 'Year', 'ISBN', 'ISSN', 'Item Type',\n",
    "       'Event Type', 'Refereed', 'Date of Award', 'Supervisor(s)',\n",
    "       'Uncontrolled Keywords', 'Subject', 'DCU Faculties and Centres',\n",
    "       'Use License', 'ID Code', 'Deposited On', 'Published in', 'Publisher',\n",
    "       'Official URL', 'Copyright Information', 'Funders',\n",
    "       'Additional Information', 'Tweets', 'Mendeley Readers']]\n",
    "\n",
    "    final = pd.concat([soc,doras_df] ,ignore_index=True)\n",
    "    final[\"Publication Title\"] = final[\"Publication Title\"].apply(lambda x: \" \".join(str(x).splitlines())) \n",
    "\n",
    "\n",
    "\n",
    "    final.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    return final \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through emperical analysis I found out  the  best suited standard Levenshtein distance similarity ratio for a particular researcher, those not in the dictionary default to 90. The process.extractone funcition of the fuzzywuzzy package automatically turns all the strings to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic = {\"Rob Brennan\": 92, \"Annalina Caputo\": 89, \"Long Cheng\":89, \"Jennifer Foster\":89, \"Jane Kernan\": 89,\"Alistair Sutherland\":88,\"Andy Way\":88,\"Murat YILMAZ\":87,\"Paul M. Clarke\":89,\"Gareth Jones\":87}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doras_soc_df is a dataframe containing the publications listed on the faculty page\n",
    "doras_soc_df =  pd.read_csv(\"../data/Doras SOC/doras_soc.csv\")\n",
    "for index, value in researchers['Researcher'].items():\n",
    "    value = value.strip()# value is the researchers name\n",
    "    doras_df = \"\"\n",
    "    scholar_df = \"\"\n",
    "    filename = \"_\".join(value.split(\" \"))\n",
    "    doras_name = \"\" # the name of the researcher in doras format\n",
    "    # need try and except as not every researcher has a doras page\n",
    "    try:\n",
    "        doras_df1 = pd.read_csv(\"../data/Doras publications/{}.csv\".format(filename))\n",
    "        doras_name = researchers.iloc[index,4].strip()\n",
    "        doras_df = reconcile_doras(value,doras_name,doras_df1,doras_soc_df)\n",
    "        doras_df = doras_df[doras_df[\"Conf/Journal Details\"].str.contains(\"preprint\", na=False) == False].reset_index(drop=True)# removing preprints\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # need try and except as not every researcher has a doras page\n",
    "    try:\n",
    "        scholar_df = pd.read_csv(\"../data/Google Scholar Publications/{}.csv\".format(filename))\n",
    "        scholar_df = scholar_df[scholar_df[\"Conf/Journal Details\"].str.contains(\"preprint\", na=False) == False].reset_index(drop=True)# removing preprints\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # testing if we have both profiles(doras and google scholar) present\n",
    "    if len(doras_df) > 0 and len(scholar_df) > 0:\n",
    "        try:\n",
    "            score = int(dic[value])\n",
    "        except KeyError:\n",
    "            score = 90\n",
    "        choices1 = doras_df[\"Publication Title\"].values.tolist()#adding all of the doras tiitles to a list\n",
    "        for index, title in scholar_df[\"Publication Title\"].items():\n",
    "            distance = process.extractOne(str(title.strip()),choices1)[-1]# the ratio score\n",
    "            nearest_title = process.extractOne(str(title.strip()),choices1)[0]# the nearest title based on the ratio\n",
    "            if distance >= score and distance < 99: # regular expression methods used to find missing publications above the threshold \n",
    "                if check_years(title,nearest_title) == True:\n",
    "                    if equal_year(title,nearest_title) == False:\n",
    "                        not_on_doras = pd.concat([not_on_doras,scholar_df.iloc[[index]]],ignore_index=True)\n",
    "                elif \"NTCIR\" in title and \"NTCIR\" in nearest_title:\n",
    "                    if check_ncir == False:\n",
    "                        not_on_doras = pd.concat([not_on_doras,scholar_df.iloc[[index]]],ignore_index=True)\n",
    "                        \n",
    "                elif \"shared task (SR\" in title and \"shared task (SR\" in nearest_title:\n",
    "                    if check_sr(title,nearest_title) == False:\n",
    "                        not_on_doras = pd.concat([not_on_doras,scholar_df.iloc[[index]]],ignore_index=True)\n",
    "                elif check_wmt(title,nearest_title) == True:\n",
    "                    if equal_wmt(title,nearest_title) == False:\n",
    "                        not_on_doras = pd.concat([not_on_doras,scholar_df.iloc[[index]]],ignore_index=True)\n",
    "                        \n",
    "                        \n",
    "                else:# ones I could not catch and were ambigious. put them in the mismatch dataframe\n",
    "                    if title == \"Universal dependencies 1.1\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Evaluation of coordination techniques in synchronous collaborative information retrieval\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Oracle-based training for phrase-based statistical machine translation\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Machine translation\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Results of the wmt18 metrics shared task: Both characters and embeddings achieve good performance\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Results of the wmt16 metrics shared task\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Interaction and engagement for information research and learning with lifelogging devices\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Multimedia for personal health and health care\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                    elif title == \"Streamrule: a nonmonotonic stream reasoning system for the semantic web\":\n",
    "                        add_mis_matches(value,title,nearest_title,distance,scholar_df[\"Year\"].loc[index])\n",
    "                   \n",
    "            \n",
    "            # adding google scholar publication titles that do not appear in doras\n",
    "            elif process.extractOne(str(title.strip()),choices1)[-1] < score:\n",
    "                not_on_doras = pd.concat([not_on_doras,scholar_df.iloc[[index]]],ignore_index=True)\n",
    "    # if a researcher has no doras profile, adding all of his/her publications to not_on_doras            \n",
    "    elif len(scholar_df) > 0 and len(doras_df)  == 0:# if they dont have a doras profile putting all of their google scholar profile papers into the not on doras df\n",
    "        not_on_doras = pd.concat([not_on_doras,scholar_df],ignore_index=True)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch dataframe\n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Mismatch Title | The title of the google scholar  paper |\n",
    "| Nearest Title | The title of the doras paper. |\n",
    "| Score | The ratio score.|\n",
    "| Year  | Year of the scholar paper. |\n",
    "\n",
    "\n",
    "## Not on doras dataframe \n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Publication title | The title of a  paper |\n",
    "| Author list | The author's of a paper.|\n",
    "| Conf/Journal Details  | Details about a publication. |\n",
    "| Citation Count  | The citation count garnered by a particular paper. |\n",
    "| Year  | Year of a paper. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Research name':list_researcher,'Mismatch Title':list_mis_match_title,'Nearest Title':list_nearest_title,'Score':list_score,\"Year\":list_year,\"Filename\":None,\"Ignore Y/N\":False}\n",
    "mis_matches_df = pd.DataFrame(data=d)\n",
    "not_on_doras[\"Filename\"] = None\n",
    "not_on_doras[\"Ignore Y/N\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mis_matches_df.to_csv(\"../data/Missing Publications/mismatches_not_on_doras.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_on_doras.to_csv(\"../data/Missing Publications/not_on_doras.csv\", index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
