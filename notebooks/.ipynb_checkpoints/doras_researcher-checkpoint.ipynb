{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doras Researcher \n",
    "Doras.dcu.ie is DCU's Institutional open research repository. \n",
    "\n",
    "**Goal:** My goal was to  scrape details about each researcher's publications on the doras website. I documented this  in a Jupyter Notebook and recorded  it in a git repository.\n",
    "\n",
    "The notebook is broken down into **five** sections:\n",
    "\n",
    "1. Importing the libaries, initializing a chrome webdriver and  creating a beautiful soup object. \n",
    "\n",
    "2. Creating methods that will help me parse the html.\n",
    "\n",
    "3. Perfoming the parsing.\n",
    "\n",
    "4. Using selenium and chrome to get additional information about a publication contained in javascript elements.\n",
    "\n",
    "5. Creating a pandas dataframe(detailed below) for each researcher.\n",
    "\n",
    "\n",
    "\n",
    "| variable | description |\n",
    "|---:|:---|\n",
    "| res | Response object|\n",
    "| soup | A beautiful soup object used for pulling data out of HTML and XML files |\n",
    "| driver | The Selenium API uses the WebDriver protocol to control a web browser, chrome in this instance. The driver is used to parse javascript elements on a page .|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "#from selenium.common.by import by\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "import selenium.webdriver.support.ui as ui\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(2)\n",
    "researchers = pd.read_csv(\"../data/SOC_Researchers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating functions that will help me parse the html\n",
    "\n",
    "The lists I have detailed,  will become  the columns of the dataframe.\n",
    "\n",
    "**Remve_orcid_number** method is used to remove the orcid number after an authors's name from the publications that belong to books.\n",
    "\n",
    "**Get_names** method is used to extract the names from each publication into a list.\n",
    "\n",
    "**Get orcid** used to find authors with orcid's and those that dont.\n",
    "\n",
    "**get_isbn** used to find isbn number of each publication.\n",
    "\n",
    "**get_issn** used to find issn number of each publication.\n",
    "\n",
    "**remove_issn_isbn** used to  get  just the conference/journal details and remove isbn/issn numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_orcid_number(list_info):\n",
    "    i = 0\n",
    "    removed = []\n",
    "    while i < len(list_info):\n",
    "        if list_info[i] == \"ORCID:\":\n",
    "            i = i + 2\n",
    "        removed.append(list_info[i]) \n",
    "        \n",
    "        i+=1\n",
    "    return removed\n",
    "\n",
    "def get_names(text):\n",
    "    list_names = []\n",
    "    for name  in text:\n",
    "        name = name.strip()\n",
    "        if \"(\" in name:\n",
    "            break\n",
    "        if not name.isspace() and name != '' and name != \"\\n\" and name != \",\" and name != \"and\" and \"ORCID:\" not in name:\n",
    "            list_names.append(name)\n",
    "    return list_names\n",
    "\n",
    "\n",
    "def get_orcid(text):\n",
    "    list_orcid_names = []\n",
    "    list_just_name = []\n",
    "    list_names = []\n",
    "    for name  in text:\n",
    "        name = name.strip()\n",
    "        if \"(\" in name:\n",
    "            break\n",
    "        if not name.isspace() and name != '' and name != \"\\n\" and name != \",\" and name != \"and\":\n",
    "            list_names.append(name)\n",
    "    i = 0\n",
    "    while i < len(list_names):\n",
    "        if \"ORCID:\" in list_names[i]:\n",
    "            list_orcid_names.append(list_names[i - 1] + \", \" + list_names[i])\n",
    "        if i != len(list_names) - 1 :\n",
    "            if \"ORCID:\"  not in list_names[i] and \"ORCID:\"  not in list_names[i + 1]:\n",
    "                list_just_name.append(list_names[i])\n",
    "        else:\n",
    "            if \"ORCID:\"  not in list_names[i]:\n",
    "                list_just_name.append(list_names[i])\n",
    "                \n",
    "            \n",
    "        i = i + 1\n",
    "        \n",
    "    return list_orcid_names,list_just_name\n",
    "\n",
    "def get_isbn(text):\n",
    "    isbn = text.split(\".\")[-1]\n",
    "    number = None\n",
    "    if \"ISBN\" in isbn:\n",
    "        number = isbn.split(\" \")[-1]\n",
    "    return number\n",
    "\n",
    "def get_issn(text):\n",
    "    issn = text.split(\".\")[-1]\n",
    "    number = None\n",
    "    if  \"ISSN\" in issn:\n",
    "        number = issn.split(\" \")[-1]\n",
    "    return number\n",
    "\n",
    "def remove_issn_isbn(text):\n",
    "    check =  text.split(\".\")[-1]\n",
    "    want =  text\n",
    "    if \"ISBN\" in check or \"ISSN\" in check:\n",
    "        want = \".\".join(text.split(\".\")[:-1])\n",
    "    return want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the parsing and using selenium to extract additional features of a publication\n",
    "\n",
    "The comments in the  code cell further down below, explain the functionality of the code used to parse the html and certain javacript elements. Publications dated from 2009 to present(inclusive) are scraped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The resulting dataframe will have these columns:\n",
    "\n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Publication title | The title of each paper |\n",
    "| Author list | The author's formated similar to the way it is presented on the doras website.|\n",
    "| Conf/Journal Details  | Details about the publication. |\n",
    "| Year  | Year of each paper publication. |\n",
    "| Full name | The author's name formated as full first name and full second name without a comma seperating the two names. |\n",
    "| Authors and Orcid  | Authors that have an orcid and their id. |\n",
    "| Authors without a orcid   | Authors that do not  have a orcid |\n",
    "| ISBN | The ISBN number of the publication. |\n",
    "| ISSN  | The ISSN number of the aplication. |\n",
    "| Item Type |Item type of the publication. |\n",
    "| Event Type | Event where the publication was showcased. |\n",
    "| Refereed | Referred |\n",
    "| Date of award | The date at which a phd or other thesis was awarded. |\n",
    "| Supervisor(s) | Supervisors of the publication |\n",
    "| Uncontrolled Keywords | Uncontrolled keywords of the publication |\n",
    "| Subject | The subjects touched on by the paper |\n",
    "| DCU Faculties and Centres | The DCU Faculties and Centres involved |\n",
    "| Use License | The use license of the publication. |\n",
    "| ID Code | The ID code of the publication. |\n",
    "| Deposited On | The date and person who entered the publication into the doras system. |\n",
    "| Published in | Details about the conference or journal |\n",
    "| Publisher | The publisher |\n",
    "| Official URL | The url of the publication |\n",
    "| Copyright Information | Copyright info of a publication |\n",
    "| Funders | The funders of the publication |\n",
    "| Additional Information | Additional information associated with the publicaton |\n",
    "| Tweets | The number of treates earned by the publication |\n",
    "| Mendeley Readers | The number of Mendeley Readers  garned by the publication | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,value in researchers['Researcher'].items():\n",
    "    list_years = [] #list of years\n",
    "    list_authors = [] # authors formated similar to the way it is presented on the doras website.\n",
    "    list_google_scholar_format = [] # authors name similar to the ones in google scholar format ie first letter of first name and full surname.\n",
    "    list_paper_title = [] # list of paper titles\n",
    "    list_journal_info = [ ] # list containg information about the publication\n",
    "    list_correct_name  = [] # authors name formated as full first name and full surname.\n",
    "    list_orcid = [] # author name and orcid\n",
    "    list_without_orcid = [] #authors that do not have a orid name \n",
    "    list_researcher = [] # just contains the researcher name\n",
    "    list_isbn = [] # list of isbn number\n",
    "    list_just_journal = [] # just the journal\n",
    "    list_isbn = [] # list of isbn numbers\n",
    "    list_issn = [] # list of issn number\n",
    "    list_item_type = [] # list of item types\n",
    "    list_event_type = [] # list of event types\n",
    "    list_refereed = [] # list of references\n",
    "    list_subjects = [] # list of subjects associated with each populication\n",
    "    list_uncontrolled_Keywords =  [] # list of uncontrolled keywords \n",
    "    lsit_subjects = [] # list of subjects \n",
    "    list_dcu_faculties_and_centres = [] # list of dcu centres involved \n",
    "    list_published_in = [] # conf/journal details\n",
    "    list_publisher = [] # publisher\n",
    "    list_official_url = [] # url of each publication\n",
    "    list_copyright_information = [] #  copyright info\n",
    "    list_use_license = [] # use license details\n",
    "    list_date_of_award = [] # list of the date a thesis was awarded\n",
    "    list_supervisors = [] # list of supervisors associated with a thesis\n",
    "    list_funders = [] # list of funders\n",
    "    list_id_code = [] # list of the unique doras id code associated with each publication\n",
    "    list_additional_information = [] # additional info \n",
    "    list_deposited_on = [] # list of  details such as the date and the person who inputed the details of the publication into the doras system\n",
    "    list_tweet = [] # list of the number of the tweets garned by each publicatiom\n",
    "    list_mendeley = [] # list of the number of meneley readers garned by each publicatiom\n",
    "\n",
    "\n",
    "    researcher = value.strip()\n",
    "    doras_link = researchers.iloc[index,2]\n",
    "    if str(doras_link) != 'nan':\n",
    "        res = requests.get(doras_link)\n",
    "        soup = BeautifulSoup(res.text,\"lxml\")\n",
    "        for header in soup.find_all('h2'): # looping through every header object to get year\n",
    "            nextNode = header\n",
    "            year = nextNode.get_text()\n",
    "            if \"2008\" in str(year):\n",
    "                break\n",
    "            while True:\n",
    "                nextNode = nextNode.nextSibling\n",
    "                # various conditions that if met the node shoud move on to the next header tag\n",
    "                if nextNode is None:\n",
    "                    break\n",
    "                if isinstance(nextNode, NavigableString):\n",
    "                    print (nextNode.strip())\n",
    "                if isinstance(nextNode, Tag):\n",
    "                    if nextNode.name == \"h2\": \n",
    "                        break\n",
    "                    elif nextNode.name == \"a\":\n",
    "                        break\n",
    "                    elif nextNode.attrs == {'class': ['ep_view_timestamp']}:\n",
    "                        break\n",
    "                if year == \"2008\":\n",
    "                    break\n",
    "                names = get_names(nextNode.find_all(text=True,))\n",
    "                names_of_paper = []# storing all of the names of that paper so we can perform string manipulation\n",
    "                google_scholar_format = []\n",
    "                correct_name = []\n",
    "                list_researcher.append(researcher)\n",
    "                with_orcid, no_orcid_name  = get_orcid(nextNode.find_all(text=True,))\n",
    "                if len(\", \".join(with_orcid).strip()) > 0:\n",
    "                    list_orcid.append(\", \".join(with_orcid).strip())\n",
    "                else:\n",
    "                    list_orcid.append(None)\n",
    "\n",
    "                journal_info=None\n",
    "                i = 0\n",
    "                while i < len(names):\n",
    "                    if i != len(names) - 1:# taking  author list and making sure it doesnt have an extra comma at end and removing the and\n",
    "                        first = names[i].split(\",\")[-1]\n",
    "                        second = names[i].split(\",\")[0]\n",
    "                        names_of_paper.append(second.strip() + \", \" + first.strip() + \", \")\n",
    "                        correct_name.append(first.strip() + \" \" + second.strip() + \", \")\n",
    "                    else:\n",
    "                        first = names[i].split(\",\")[-1]\n",
    "                        second = names[i].split(\",\")[0]\n",
    "                         \n",
    "                        names_of_paper.append(second.strip() + \", \" + first.strip())\n",
    "                        correct_name.append(first.strip() + \" \" + second.strip())\n",
    "                    i = i + 1\n",
    "\n",
    "                #turniing the list of authors into a string representation\n",
    "                names_of_paper = \"\".join(names_of_paper).strip()\n",
    "\n",
    "                correct_name = \"\".join(correct_name)\n",
    "\n",
    "                #adding the names to the revalent lists\n",
    "                list_authors.append(names_of_paper)\n",
    "                list_google_scholar_format.append(google_scholar_format)\n",
    "                list_correct_name.append(correct_name)\n",
    "\n",
    "                #adding the correct year\n",
    "                list_years.append(int(year))\n",
    "\n",
    "                #authors that do not have a orcid \n",
    "                if len(\", \".join(no_orcid_name).strip())> 0:\n",
    "                    list_without_orcid.append(\", \".join(no_orcid_name).strip())\n",
    "                else:\n",
    "                    list_without_orcid.append(None)\n",
    "                    \n",
    "                #adding extra information to each publication that is detailed in the link attached to each publication title    \n",
    "                extra_link = None\n",
    "                if len(nextNode.find_all('a')) > 1:\n",
    "                    for link in nextNode.find_all('a'):\n",
    "                        if \"doras\" in str(link[\"href\"]):\n",
    "                            extra_link = link[\"href\"]\n",
    "                else:\n",
    "                    extra_link = nextNode.find(\"a\")[\"href\"]\n",
    "                # down below is a list of all of the additional features scraped from a publication info page.\n",
    "                num_tweet = None\n",
    "                num_mend = None    \n",
    "                item_type = None\n",
    "                event_type = None\n",
    "                refereed = None\n",
    "                uncontrolled_Keywords = None\n",
    "                subjects = None\n",
    "                dcu_faculties_and_centres = None\n",
    "                published_in = None\n",
    "                publisher = None\n",
    "                official_url = None\n",
    "                copyright_information = None\n",
    "                use_license = None\n",
    "                date_of_award = None\n",
    "                supervisors = None\n",
    "                funders = None\n",
    "                id_code = None\n",
    "                additional_information = None\n",
    "                deposited_on = None\n",
    "                driver.get(extra_link)\n",
    "                time.sleep(2 + random.uniform(0,6))\n",
    "                soupes = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                # not every publication had such features\n",
    "                try:\n",
    "                    num_tweet = soupes.find(\"div\", class_=\"altmetric_row altmetric_tweeters\").get_text()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                try:\n",
    "                    num_mend = soupes.find(\"div\", class_=\"altmetric_row altmetric_mendeley\").get_text()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                table = soupes.find('table',class_= \"ep_block\",style=\"margin-bottom: 1em; text-align:left;\",border=\"0\" )\n",
    "                for row in table.find_all(\"tr\"):\n",
    "                    descript = row.find(\"th\", class_=\"ep_row\").get_text().strip()\n",
    "                    value = row.find('td', class_=\"ep_row\").get_text().strip()\n",
    "\n",
    "                    if descript == 'Item Type:':\n",
    "                        item_type = value\n",
    "\n",
    "                    if descript == \"Event Type:\":\n",
    "                        event_type = value\n",
    "\n",
    "\n",
    "                    if descript == 'Date of Award:' :\n",
    "                        date_of_award = value\n",
    "                    if descript == \"Refereed:\":\n",
    "                        refereed = value\n",
    "                    if descript == \"Supervisor(s):\":\n",
    "                        supervisors = value\n",
    "                    if descript == \"Uncontrolled Keywords:\":\n",
    "                        uncontrolled_Keywords = value\n",
    "\n",
    "                    if descript == \"Subjects:\":\n",
    "                        if len(row.find_all(\"a\")) <= 1:\n",
    "                            subjects = value\n",
    "                        else:\n",
    "                            subjects = \"\"\n",
    "                            for text in row.find_all(\"a\"):\n",
    "                                subjects += text.get_text().strip() + \". \"\n",
    "\n",
    "                    if descript == 'DCU Faculties and Centres:':\n",
    "                        if len(row.find_all(\"a\")) <= 1:\n",
    "                            dcu_faculties_and_centres = value\n",
    "                        else:\n",
    "                            dcu_faculties_and_centres = \"\"\n",
    "                            for text in row.find_all(\"a\"):\n",
    "                                dcu_faculties_and_centres += text.get_text().strip() + \". \"\n",
    "\n",
    "\n",
    "                    if descript == \"Use License:\":\n",
    "                        use_license = value\n",
    "\n",
    "                    if  descript == \"ID Code:\":\n",
    "                        id_code = value\n",
    "\n",
    "                    if descript == \"Deposited On:\":\n",
    "                        deposited_on = \" \".join([item.replace(\"\\n\",\"\").strip() for item in value.split(\" \") if item != \"\" or item !=''])\n",
    "\n",
    "                    if descript == \"Published in:\":\n",
    "                        published_in = \" \".join([item.replace(\"\\n\",\"\").strip() for item in value.split(\" \") if item != \"\" or item !=''])\n",
    "\n",
    "                    if descript == \"Publisher:\":\n",
    "                        publisher = value\n",
    "                    if descript == \"Official URL:\":\n",
    "                        official_url = value\n",
    "\n",
    "                    if descript == \"Copyright Information:\":\n",
    "                        copyright_information = value\n",
    "\n",
    "\n",
    "                    if descript == \"Funders:\":\n",
    "                        funders = value\n",
    "\n",
    "\n",
    "                    if descript == \"Additional Information:\":\n",
    "                        additional_information = value\n",
    "                #appending additional features to their respective lists\n",
    "                list_item_type.append(item_type)\n",
    "                list_event_type.append(event_type)\n",
    "                list_refereed.append(refereed)\n",
    "                list_uncontrolled_Keywords.append(uncontrolled_Keywords)\n",
    "                lsit_subjects.append(subjects)\n",
    "                list_dcu_faculties_and_centres.append(dcu_faculties_and_centres)\n",
    "                list_published_in.append(published_in)\n",
    "                list_publisher.append(publisher)\n",
    "                list_official_url.append(official_url)\n",
    "                list_copyright_information.append(copyright_information)\n",
    "                list_use_license.append(use_license)\n",
    "                list_date_of_award.append(date_of_award)\n",
    "                list_supervisors.append(supervisors)\n",
    "                list_funders.append(funders)\n",
    "                list_id_code.append(id_code)\n",
    "                list_additional_information.append(additional_information)\n",
    "                list_deposited_on.append(deposited_on)\n",
    "                list_subjects.append(subjects)\n",
    "                list_tweet.append(num_tweet)\n",
    "                list_mendeley.append(num_mend)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # getting the title of the paper\n",
    "                paper_title = nextNode.find(\"em\")\n",
    "                #adding paper title to a list of paper titles\n",
    "                list_paper_title.append(paper_title.get_text().strip())\n",
    "\n",
    "                #info and information represent the publication's information at different cleaning stages.\n",
    "                info = str(nextNode.find('em').next.next.strip())\n",
    "                information = [ inc.strip() for inc in info.split(\" \") if not inc.isspace() and inc != '' ]\n",
    "\n",
    "                #information is a list of journal info\n",
    "                #checking that it is not a book\n",
    "                if len(information) > 0: \n",
    "                    if information[0] == 'In:':\n",
    "                        information =information[1:] # removing \"In:\"\n",
    "                        journal_info = \" \".join(information) #  details about the journal inluding details such as date and ISBN   \n",
    "                    elif information[0] == 'PhD':# PhD's treated differently\n",
    "                        journal_info = \" \".join(information)\n",
    "                    else:\n",
    "                        journal_info = \" \".join(information)\n",
    "                elif len(information) == 0: # testing if its a book rather than a journal\n",
    "                    lines = nextNode.find_all(text=True,) # lines below are my cleaning process for book's\n",
    "                    i = 0\n",
    "                    position = 0\n",
    "                    wanted = []\n",
    "                    while i < len(lines):\n",
    "                        line = lines[i].strip()\n",
    "                        wanted.append(lines[i])\n",
    "                        if line == 'In: <if test=\"!is_set(creators)\"><print expr=\"editors_name\"/>, (ed<if test=\"length(editors_name) gt 1\">s</if>.)</if>':\n",
    "                            position = i + 1\n",
    "                        i += 1\n",
    "                    wanted = \"\".join(wanted[position:])\n",
    "                    position = 0\n",
    "                    info_want = []\n",
    "                    for want in wanted.split(\" \"):\n",
    "                        if not want.isspace() and want != '' and want != \"\\n\":\n",
    "                                info_want.append(want.strip())\n",
    "                    info_want = remove_orcid_number(info_want)\n",
    "                    info_want = info_want[1:]# removing \"In:\"\n",
    "                    journal_info = \" \".join(info_want)\n",
    "\n",
    "                # adding journal info to a list of journal information\n",
    "                list_journal_info.append(remove_issn_isbn(journal_info.strip()))\n",
    "\n",
    "                isbn_num = get_isbn(journal_info.strip())\n",
    "                list_isbn.append(isbn_num)\n",
    "                issn_num = get_issn(journal_info.strip())\n",
    "                list_issn.append(issn_num)\n",
    "\n",
    "\n",
    "        d = {\"Research name\": list_researcher, \"Publication Title\": list_paper_title,  \"Author List\": list_authors, \"Conf/Journal Details\": list_journal_info,  \"Year\":list_years, \"Full name\":list_correct_name, \"Authors and Orcid\":list_orcid, \"Authors without a orcid\": list_without_orcid, \"ISBN\": list_isbn, \"ISSN\": list_issn,'Item Type': list_item_type, \"Event Type\":list_event_type,\"Refereed\":list_refereed,'Date of Award': list_date_of_award,\"Supervisor(s)\":list_supervisors, \"Uncontrolled Keywords\":list_uncontrolled_Keywords, \"Subject\" :list_subjects,'DCU Faculties and Centres': list_dcu_faculties_and_centres,\"Use License\" :list_use_license,\"ID Code\": list_id_code,\"Deposited On\": list_deposited_on, \"Published in\":list_published_in,\"Publisher\":list_publisher,\"Official URL\":list_official_url,\"Copyright Information\":list_copyright_information,\"Funders\":list_funders,\"Additional Information\":list_additional_information,\"Tweets\":list_tweet,\"Mendeley Readers\":list_mendeley}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df = df[df.Year >= 2009]\n",
    "        filename = \"_\".join(researcher.split(\" \"))\n",
    "        df.to_csv(\"../data/Doras publications/{}.csv\".format(filename), index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
