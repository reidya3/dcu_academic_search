{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google scholar webscraper\n",
    "\n",
    "Google Scholar is a freely accessible web search engine that indexes the full text or metadata of scholarly literature across an array of publishing formats and disciplines.\n",
    "\n",
    "This notebook contains **five** key elements:\n",
    "\n",
    "1. Importing the libaries and initializing a chrome webdriver. \n",
    "\n",
    "2. Using selenium to max out the see more button \n",
    "\n",
    "3. Creating a beautiful soup object\n",
    "\n",
    "4. Perfoming the parsing.\n",
    "\n",
    "5. Creating a pandas dataframe(detailed below) for each researcher.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "import selenium.webdriver.support.ui as ui\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xpath of show more button and the x of the 'more details' path\n",
    "show_more_button_path = '/html/body/div/div[13]/div[2]/div/div[4]/form/div[2]/div/button'\n",
    "x_button_path = '/html/body/div/div[8]/div/div[1]/a'\n",
    "year_button_path = '/html/body/div/div[13]/div[2]/div/div[4]/form/div[1]/table/thead/tr[2]/th[3]/span/a'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The resulting dataframe will have these columns:\n",
    "\n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Publication title | The title of a  paper |\n",
    "| Author list | The author's of a paper.|\n",
    "| Conf/Journal Details  | Details about a publication. |\n",
    "| Citation Count  | The citation count garnered by a particular paper. |\n",
    "| Year  | Year of a paper. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researchers = pd.read_csv(\"../data/SOC_Researchers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_capitals(l):# adds capitals to author name, cutting down the number of alias's\n",
    "    if l.isupper():\n",
    "        l = l.lower()\n",
    "        l =  l.title()\n",
    "    else:\n",
    "        l = l.title()\n",
    "    return l\n",
    "alias_authors = pd.read_excel(\"../data/Neo4j/alias_author_excel.xlsx\") \n",
    "alias_authors[\"Alias\"] = alias_authors[\"Alias\"].apply(lambda x: x.strip())# removing whitespaces\n",
    "alias_authors[\"Author\"] = alias_authors[\"Author\"].apply(lambda x: x.strip())\n",
    "alias_dict = dict(zip(alias_authors[\"Alias\"].tolist(), alias_authors[\"Author\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,value in researchers['Researcher'].items():\n",
    "    name = value.strip()\n",
    "    google_scholar_link = researchers.iloc[index,1]\n",
    "    if str(google_scholar_link) != 'nan':\n",
    "        driver.get(google_scholar_link)\n",
    "        time.sleep(5+ random.uniform(0,20))\n",
    "        #maxing out the show more button\n",
    "        show_more_button = driver.find_element_by_xpath(show_more_button_path)\n",
    "        time.sleep(2)\n",
    "        while show_more_button.get_attribute('disabled') == None:\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, show_more_button_path))).click()\n",
    "            time.sleep(3+ random.uniform(0,1))\n",
    "            show_more_button = driver.find_element_by_xpath(show_more_button_path)\n",
    "        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,year_button_path))).click()\n",
    "        time.sleep(2)\n",
    "        text = driver.page_source\n",
    "        list_researcher_name = []\n",
    "        list_paper_title = [] \n",
    "        list_year = []\n",
    "        list_authors = []\n",
    "        list_journal_info = []\n",
    "        list_count_cit = []\n",
    "        list_only_journal = []\n",
    "        soup =  BeautifulSoup(text,\"lxml\")\n",
    "        i = 1\n",
    "        for instance in soup.find_all('tr', class_='gsc_a_tr'):\n",
    "            #adding research name\n",
    "            list_researcher_name.append(name)\n",
    "\n",
    "            # finding authors names\n",
    "            more_details_button = \"/html/body/div/div[13]/div[2]/div/div[4]/form/div[1]/table/tbody/tr[{}]/td[1]/a\".format(i)\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,more_details_button))).click()\n",
    "            time.sleep(5 + random.uniform(0,5))\n",
    "            more_details_soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            authors = None\n",
    "            for extra_instance in more_details_soup.find_all(\"div\", class_=\"gs_scl\"):\n",
    "                if extra_instance.find('div', class_=\"gsc_vcd_field\"):\n",
    "                    if extra_instance.find('div', class_=\"gsc_vcd_field\").get_text() == \"Authors\":\n",
    "                        authors = extra_instance.find('div', class_=\"gsc_vcd_value\").get_text().strip()\n",
    "                    elif extra_instance.find('div', class_=\"gsc_vcd_field\").get_text() == \"Inventors\":\n",
    "                        authors = extra_instance.find('div', class_=\"gsc_vcd_value\").get_text().strip()\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, x_button_path))).click()\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                list_authors.append(authors.replace(u'\\xa0', u' ').strip())\n",
    "            except AttributeError:\n",
    "                list_authors.append(name)\n",
    "\n",
    "            #--OLD FINDING AUTHORS METHOD-----\n",
    "            # finding authors names\n",
    "            #authors =instance.find('div', class_='gs_gray')\n",
    "            #list_authors.append(authors.get_text().replace(u'\\xa0', u' ').strip())\n",
    "\n",
    "            #finding the papers title\n",
    "            paper_title = instance.find(\"a\", class_= \"gsc_a_at\")\n",
    "            list_paper_title.append(paper_title.get_text().replace(u'\\xa0', u' ').strip())\n",
    "\n",
    "            #getting year\n",
    "            year = instance.find(\"span\", class_=\"gsc_a_h gsc_a_hc gs_ibl\")\n",
    "            if len(year) > 0:\n",
    "                list_year.append(int(year.get_text().strip()))\n",
    "            else:\n",
    "                list_year.append(None)\n",
    "\n",
    "            #finding the journal name\n",
    "            journal_info =instance.find_all('div', class_='gs_gray')[1]\n",
    "            if journal_info:\n",
    "                list_journal_info.append(journal_info.get_text().replace(u'\\xa0', u' ').strip())\n",
    "                if year:\n",
    "                    list_only_journal.append(\"\".join(journal_info.get_text().replace(u'\\xa0', u' ').strip().split(\",\")[:-1]))\n",
    "                else:\n",
    "                    list_only_journal.append(journal_info.get_text().replace(u'\\xa0', u' ').strip())\n",
    "\n",
    "            else:\n",
    "                list_journal_info.append(None)\n",
    "                list_only_journal.append(None)\n",
    "\n",
    "\n",
    "            #getting count of citations\n",
    "            count_cit = instance.find('a', class_=\"gsc_a_ac gs_ibl\")\n",
    "            # checking if its not just a line through citation\n",
    "            if count_cit == None:\n",
    "                count_cit = instance.find('a', class_=\"gsc_a_ac gs_ibl gsc_a_acm\")\n",
    "            if len(count_cit) > 0:\n",
    "                list_count_cit.append(count_cit.get_text().strip())\n",
    "            else:\n",
    "                list_count_cit.append(0)\n",
    "\n",
    "            i+=1 # used to find the title xpath link\n",
    "\n",
    "        d = {\"Research name\":list_researcher_name,\"Publication Title\": list_paper_title,\"Author List\": list_authors, \"Conf/Journal Details\": list_only_journal, \"Citation count\": list_count_cit, \"Year\":list_year }\n",
    "        df = pd.DataFrame(data=d)\n",
    "        pd.to_numeric(df.Year , errors='coerce')\n",
    "        df = df[df.Year > 2008]\n",
    "        df = df.sort_values(by=['Year'], ascending=False)\n",
    "        #alias to canocial method\n",
    "        for index, authors in df[\"Author List\"].items():\n",
    "            list_authors = []# a list of authors on a publication\n",
    "            # have to replace diffferent kind of apostrophe to one \n",
    "            for author in authors.split(\", \"):\n",
    "                author = author.replace(\"'\",\"â€™\").strip()\n",
    "                author = add_capitals(author).strip()\n",
    "                if author in alias_dict:\n",
    "                    author = alias_dict[author]#changing to Cannon name\n",
    "                list_authors.append(author)\n",
    "            df.loc[index,\"Author List\"] = \", \".join(list_authors)#changing the scholar dataframe to replace aliases with cannon names\n",
    "            \n",
    "        filename = \"_\".join(name.split(\" \"))\n",
    "        df.to_csv(\"../data/Google Scholar Publications/{}.csv\".format(filename), index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
