{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not On Google Scholar \n",
    "\n",
    "This notebook details the method used to find missing publications on google scholar. For finding the missing publications, I used the standard Levenshtein distance similarity ratio and regular expressions. I had to specify specific thresholds for certain researchers, however, the majority were set at  a default (90). However, there were some rogue publications that were above such a threshold but still dissimilar. I hardcoded such files into  a csv file called  mismatches_not_on_google_scholar. This may a problem for future iterations. I tried other methods such as  the cosine similarity ratio using word n-gram, character n-grams and ‘char_wb’( which creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space) to try and catch the rogue publications .  However, none provided a  clear threshold  for which I  could separate the rogues from the similar publications and in some cases, the cosine similarity ratio did not find the nearest title!\n",
    "\n",
    "\n",
    "\n",
    "This notebook contains **three** key components:\n",
    "\n",
    "1. Creating methods that will help me identify the missing and rogue publications. In addition, recounciling the two versions of \n",
    "   doras (the faculty page and a researcher's page) as there are some publications that appeared in a researchers page that did not appear in the faculty page and vice versa. I also dropped redundant columns.\n",
    "\n",
    "2. Perfoming the splitting.\n",
    "\n",
    "3. Creating a pandas dataframe(detailed below) for the missing google scholar and rogue scholar publications.\n",
    "\n",
    "As it turns out, I found no rogue publications. Neverthless I still created one for future iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "researchers = pd.read_csv(\"../data/SOC_Researchers_with_doras_names.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe containing publications that are in a researcher's doras profile/faculty page but not on their google scholar profile \n",
    "not_on_google_scholar =pd.DataFrame(columns=['Research name','Publication Title','Author List','Conf/Journal Details','Year','ISBN', 'ISSN', 'Item Type',\n",
    "       'Event Type', 'Refereed', 'Date of Award', 'Supervisor(s)',\n",
    "       'Uncontrolled Keywords', 'Subject', 'DCU Faculties and Centres',\n",
    "       'Use License', 'ID Code', 'Deposited On', 'Published in', 'Publisher',\n",
    "       'Official URL', 'Copyright Information', 'Funders',\n",
    "       'Additional Information', 'Tweets', 'Mendeley Readers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating functions that will find the missing google scholar  publications and reconcile the  two versions of Doras \n",
    "\n",
    "**add_mis_matches** method that assists in the development of a dataframe that contains  mismatched/rogue publications\n",
    "\n",
    "**check_years** checks if there is a year present in the doras publication title and the nearest publication title on google scholar.\n",
    "\n",
    "**equal_years**  tests if the year in a doras title and the year in  the nearest scholar publication title in doras are the same\n",
    "\n",
    "**check_ncir** another method testing whether the year in a publications title containing \"NICIR\" and the year in the nearest publication title on google scholar  are the same. Note, the year is in the format NCIR-19 (for example) so I could not simply use the method above.\n",
    "\n",
    "**check_sr** another method testing whether the year in a publications title containing \"shared task (SR\" and the year in the nearest publication title on google scholar  are the same. Note, the year is in the format SR'19 or SR’19 so so I could not simply use the method above.\n",
    "\n",
    "**check_wmt** checks whether a doras publication title  contains wmt and the nearest publication title on google scholar also contain wmt\n",
    "\n",
    "**equal_wmt**  another method testing whether the year in a publications title containing \"wmt\" and the year in the nearest publication title on google scholar are the same. Note, the year is in the format SR'19 or SR’19 so so I could not simply used the method above.\n",
    "\n",
    "**reconcile_doras** a method used to recouncile the two versions of doras (the faculty page and a researcher's page) as there are some publications that appeared in a researchers page that did not appear in the faculty page and vice versa. I also dropped redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mis_match_title = []\n",
    "list_nearest_title  = []\n",
    "list_score = []\n",
    "list_researcher = []\n",
    "list_year = []\n",
    "# method that assists in the development of a dataframe that contains  mismatched publications\n",
    "def add_mis_matches(research, title,near,score,year):\n",
    "    list_researcher.append(research)\n",
    "    list_mis_match_title.append(title)\n",
    "    list_nearest_title.append(near)\n",
    "    list_score.append(score)\n",
    "    list_year.append(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if there is a year present in the publication title and the nearest publication title on google scholar\n",
    "def check_years(title,near_title):\n",
    "    try:\n",
    "        year1 = re.findall(\"[2][0-9]{3}\",title)[0]\n",
    "        year2 = re.findall(\"[2][0-9]{3}\",near_title)[0]\n",
    "    except IndexError:\n",
    "        return False\n",
    "    return True\n",
    "# tests if the year in a publications title and the year in  the nearest publication title on google scholar are the same\n",
    "def equal_year(title,near_title):\n",
    "    year1 = re.findall(\"[2][0-9]{3}\",title)[0]\n",
    "    year2 = re.findall(\"[2][0-9]{3}\",near_title)[0]\n",
    "    return year1 == year2\n",
    "#another method testing whether the year in a publications title containing \"NICIR\" and the year in the nearest publication title on google scholar are the same \n",
    "def check_ncir(title,near_title):\n",
    "    year1 = re.findall(\"NTCIR-[0-9]{2}\",title)[0]\n",
    "    year2 = re.findall(\"NTCIR-[0-9]{2}\",near_title)[0]\n",
    "    return year1 == year2\n",
    "##another method testing whether the year in a publications title containing \"shared task (SR\" and the year in the nearest publication title on google scholar are the same \n",
    "def check_sr(title, near_title):\n",
    "    year1 = re.findall(\"(SR[’|'][0-9]{2})\",title)[0][-2:]\n",
    "    year2 = re.findall(\"(SR[’|'][0-9]{2})\",near_title)[0][-2:]\n",
    "    return year1 == year2\n",
    "# checks whether a  publication title  contains wmt and the nearest publication title in google scholar also contain wmt\n",
    "def check_wmt(title, near_title):\n",
    "    try:\n",
    "        year1 = re.findall(\"wmt[0-9]{2}\",title.lower())[0][-2:]\n",
    "        year2 = re.findall(\"wmt[0-9]{2}\",near_title.lower())[0][-2:]\n",
    "    except IndexError:\n",
    "        return False\n",
    "    return True\n",
    "# another method testing whether the year in a publications title containing \"wmt\" and the year in the nearest publication title in  are the same \n",
    "def equal_wmt(title,near_title):\n",
    "        year1 = re.findall(\"wmt[0-9]{2}\",title.lower())[0][-2:]\n",
    "        year2 = re.findall(\"wmt[0-9]{2}\",near_title.lower())[0][-2:]\n",
    "        return year1 == year2\n",
    "    \n",
    "# recounciling the doras profile verion and doras faculty page as there is publications that do not appear on both!\n",
    "def reconcile_doras(value,doras_name,doras_df,doras_soc_df):\n",
    "    soc = doras_soc_df[doras_soc_df[\"Author List\"].str.contains(doras_name)]\n",
    "\n",
    "    soc = soc[[\n",
    "     'Publication Title',\n",
    "     'Author List',\n",
    "     'Conf/Journal Details',\n",
    "     'Year',\n",
    "     'ISBN',\n",
    "     'ISSN',\n",
    "     'Item Type',\n",
    "     'Event Type',\n",
    "     'Refereed',\n",
    "     'Date of Award',\n",
    "     'Supervisor(s)',\n",
    "     'Uncontrolled Keywords',\n",
    "     'Subject',\n",
    "     'DCU Faculties and Centres',\n",
    "     'Use License',\n",
    "     'ID Code',\n",
    "     'Deposited On',\n",
    "     'Published in',\n",
    "     'Publisher',\n",
    "     'Official URL',\n",
    "     'Copyright Information',\n",
    "     'Funders',\n",
    "     'Additional Information',\n",
    "     'Tweets',\n",
    "     'Mendeley Readers']]\n",
    "\n",
    "    soc.insert(0, 'Research name', value)\n",
    "\n",
    "\n",
    "    doras_df = doras_df[['Research name', 'Publication Title', 'Author List',\n",
    "       'Conf/Journal Details', 'Year', 'ISBN', 'ISSN', 'Item Type',\n",
    "       'Event Type', 'Refereed', 'Date of Award', 'Supervisor(s)',\n",
    "       'Uncontrolled Keywords', 'Subject', 'DCU Faculties and Centres',\n",
    "       'Use License', 'ID Code', 'Deposited On', 'Published in', 'Publisher',\n",
    "       'Official URL', 'Copyright Information', 'Funders',\n",
    "       'Additional Information', 'Tweets', 'Mendeley Readers']]\n",
    "\n",
    "    final = pd.concat([soc,doras_df] ,ignore_index=True)\n",
    "    final[\"Publication Title\"] = final[\"Publication Title\"].apply(lambda x: \" \".join(str(x).splitlines()))\n",
    "\n",
    "\n",
    "\n",
    "    final.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    return final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through emperical analysis, I found out  the best suited standard Levenshtein distance similarity ratio, those not in the dictionary default to 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"Suzanne Little\":92}\n",
    "doras_soc_df =  pd.read_csv(\"../data/Doras SOC/doras_soc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in researchers['Researcher'].items():\n",
    "    value = value.strip()# value is the researchers name\n",
    "    doras_df = \"\"\n",
    "    scholar_df = \"\"\n",
    "    filename = \"_\".join(value.split(\" \"))\n",
    "    doras_name = \"\" # the name of the researcher in doras format \n",
    "    # need try and except as not every researcher has a doras page\n",
    "    try:\n",
    "        doras_df1 = pd.read_csv(\"../data/Doras publications/{}.csv\".format(filename))\n",
    "        doras_name = researchers.iloc[index,4].strip()\n",
    "        doras_df = reconcile_doras(value,doras_name,doras_df1,doras_soc_df)\n",
    "        doras_df = doras_df[doras_df[\"Conf/Journal Details\"].str.contains(\"preprint\", na=False) == False].reset_index(drop=True)# removing preprints\n",
    "        \n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # need try and except as not every researcher has a doras page\n",
    "    try:\n",
    "        scholar_df = pd.read_csv(\"../data/Google Scholar Publications/{}.csv\".format(filename))\n",
    "        scholar_df = scholar_df[scholar_df[\"Conf/Journal Details\"].str.contains(\"preprint\", na=False) == False].reset_index(drop=True)# removing preprints\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # testing if we have both profiles(doras and google scholar) present\n",
    "    if len(doras_df) > 0 and len(scholar_df) > 0:\n",
    "        try:\n",
    "            score = int(dic[value])\n",
    "        except KeyError:\n",
    "            score = 90\n",
    "        choices1 = scholar_df[\"Publication Title\"].values.tolist() #adding all of the google scholar tiitles to a list\n",
    "        for index, title in doras_df[\"Publication Title\"].items():# testing for missing publications above the threshold\n",
    "            distance = process.extractOne(str(title.strip()),choices1)[-1] # the ratio score\n",
    "            nearest_title = process.extractOne(str(title.strip()),choices1)[0] #the nearest title based on the ratio\n",
    "            if distance >= score and distance < 99:\n",
    "                if check_years(title,nearest_title) == True:\n",
    "                    if equal_year(title,nearest_title) == False:\n",
    "                        not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df.iloc[[index]]],ignore_index=True)\n",
    "                elif \"NTCIR\" in title and \"NTCIR\" in nearest_title:\n",
    "                    if check_ncir == False:\n",
    "                        not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df.iloc[[index]]],ignore_index=True)\n",
    "                elif \"shared task (SR\" in title and \"shared task (SR\" in nearest_title:\n",
    "                    if check_sr(title,nearest_title) == False:\n",
    "                        not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df.iloc[[index]]],ignore_index=True)\n",
    "                elif check_wmt(title,nearest_title) == True:\n",
    "                    if equal_wmt(title,nearest_title) == False:\n",
    "                        not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df.iloc[[index]]],ignore_index=True)\n",
    "                                 \n",
    "              # adding google  titles that do not appear in google scholar\n",
    "            if process.extractOne(str(title.strip()),choices1)[-1] < score:\n",
    "                not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df.iloc[[index]]],ignore_index=True)\n",
    "                \n",
    "    elif len(scholar_df) == 0 and len(doras_df)  > 0:# if they dont have a google scholar profile putting all of their doras papers into the not on google scholar df\n",
    "        not_on_google_scholar = pd.concat([not_on_google_scholar,doras_df],ignore_index=True)\n",
    "        \n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch dataframe\n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Mismatch Title | The title of the google scholar  paper |\n",
    "| Nearest Title | The title of the doras paper. |\n",
    "| Score | The ratio score.|\n",
    "| Year  | Year of the scholar paper. \n",
    "\n",
    "## Not on google scholar dataframe\n",
    "| Column name | description |\n",
    "|---:|:---|\n",
    "| Research name | The researcher's name.|\n",
    "| Publication title | The title of each paper |\n",
    "| Author list | The author's formated similar to the way it is presented on the doras website.|\n",
    "| Conf/Journal Details  | Details about the publication. |\n",
    "| Year  | Year of each paper publication. |\n",
    "| ISBN | The ISBN number of the publication. |\n",
    "| ISSN  | The ISSN number of the aplication. |\n",
    "| Item Type |Item type of the publication. |\n",
    "| Event Type | Event where the publication was showcased. |\n",
    "| Refereed | Referred |\n",
    "| Date of award | The date at which a phd or other thesis was awarded. |\n",
    "| Supervisor(s) | Supervisors of the publication |\n",
    "| Uncontrolled Keywords | Uncontrolled keywords of the publication |\n",
    "| Subject | The subjects touched on by the paper |\n",
    "| DCU Faculties and Centres | The DCU Faculties and Centres involved |\n",
    "| Use License | The use license of the publication. |\n",
    "| ID Code | The ID code of the publication. |\n",
    "| Deposited On | The date and person who entered the publication into the doras system. |\n",
    "| Published in | Details about the conference or journal |\n",
    "| Publisher | The publisher |\n",
    "| Official URL | The url of the publication |\n",
    "| Copyright Information | Copryight info of a publication |\n",
    "| Funders | The funders of the publication |\n",
    "| Additional Information | Additional information associated with the publicaton |\n",
    "| Tweets | The number of treates earned by the publication |\n",
    "| Mendeley Readers | The number of Mendeley Readers  garned by the publication | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Research name':list_researcher,'Mismatch Title':list_mis_match_title,'Nearest Title':list_nearest_title,'Score':list_score,\"Year\":list_year}\n",
    "mis_matches_df = pd.DataFrame(data=d)\n",
    "\n",
    "mis_matches_df.to_csv(\"../data/Missing Publications/mismatches_not_on_google_scholar.csv\", index = None, header=True)\n",
    "\n",
    "not_on_google_scholar.to_csv(\"../data/Missing Publications/not_on_google_scholar.csv\", index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
